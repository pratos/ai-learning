# AI Learning

Learnings from implementing deep learning models from scratch.

## ğŸ“ Project Structure

```
ai-learning/
â”œâ”€â”€ src/encoding_101/
â”‚   â”œâ”€â”€ models/              # Autoencoder implementations
â”‚   â”‚   â”œâ”€â”€ base.py         # Base autoencoder class
â”‚   â”‚   â”œâ”€â”€ vanilla_autoencoder.py
â”‚   â”‚   â””â”€â”€ nvtx_autoencoder.py  # NVTX-annotated version
â”‚   â”œâ”€â”€ training/           # Training utilities
â”‚   â”œâ”€â”€ data.py              # Data loading and preprocessing
â”‚   â”œâ”€â”€ metrics.py         # Evaluation metrics (MAR@5)
â”‚   â””â”€â”€ visualization/     # Plotting and analysis tools
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ profile_training.py # NVTX profiling script
â”œâ”€â”€ learning/              # Learning materials and guides
â””â”€â”€ logs/                  # Training logs and checkpoints
â””â”€â”€ data/                  # All the data stored here
```

---

## ğŸ” NVTX Profiling for Performance Optimization

NVTX (NVIDIA Tools Extension) annotations provide semantic information about your training loop, enabling detailed performance analysis and bottleneck identification.

### What NVTX Gives You

Without NVTX annotations, GPU profilers show you raw kernels with no context:
- `volta_sgemm_128x64_tn`, `cudnn_conv_forward_kernel`
- Anonymous blocks of computation time
- No indication of which operation belongs to forward pass, backward pass, or data loading

With NVTX annotations, you get:
- **Semantic labels**: "Forward Pass", "Backward Pass", "MAR@5 Computation"
- **Hierarchical structure**: Nested annotations showing operation relationships
- **Performance attribution**: Clear identification of time-consuming operations
- **Color-coded timeline**: Visual distinction between different operation types

### ğŸ¨ NVTX Color Scheme

| Operation | Color | Purpose |
|-----------|-------|---------|
| Training Steps | Green | Forward/backward training passes |
| Validation | Blue | Validation forward passes |
| Forward Pass | Yellow | Model forward computation |
| Loss Computation | Orange | Loss calculation |
| Metrics | Purple | MAR@5 and other metrics |
| Visualization | Pink | Image processing and logging |
| Data Transfer | Cyan | CPUâ†”GPU data movement |
| Memory Ops | Magenta | Memory allocation tracking |

### ğŸ“Š Using NVTX Profiling

```bash
# Profile your training with NVTX annotations
nsys profile --trace=nvtx,cuda python scripts/profile_training.py profile

# Analyze results with Nsight Systems
nsys-ui <generated_file>.qdrep
```

### ğŸ” What to Look for in Profiling Results

#### Timeline Analysis
1. **GPU Utilization**: Should be >80% during forward/backward passes
2. **Data Loading**: Should not block training (overlap with computation)
3. **Memory Transfers**: Minimize CPUâ†”GPU transfers
4. **Synchronization Points**: Identify unnecessary `torch.cuda.synchronize()` calls

#### Performance Bottlenecks
- **Long data loading times**: Increase `num_workers` or optimize data pipeline
- **Low GPU utilization**: Check for CPU bottlenecks or small batch sizes
- **Memory issues**: Look for large allocations or memory fragmentation
- **Excessive visualization**: MAR@5 computation taking too long

#### NVTX Annotation Hierarchy
```
Training Step
â”œâ”€â”€ Data Unpack          [should be fast]
â”œâ”€â”€ Forward Pass         [main computation]
â”‚   â”œâ”€â”€ Encoder Forward  [first half]
â”‚   â””â”€â”€ Decoder Forward  [second half]
â”œâ”€â”€ Loss Computation     [should be minimal]
â””â”€â”€ Validation (every epoch)
    â”œâ”€â”€ MAR@5 Computation [periodic, can be expensive]
    â””â”€â”€ Visualization     [periodic, I/O bound]
```

### âš ï¸ Common Issues

#### NVTX Not Showing
- **Problem**: Annotations don't appear in Nsight Systems
- **Solution**: Ensure you're using `--trace=nvtx` flag and NVTX package is installed

#### Performance Overhead
- **Problem**: NVTX annotations slow down training
- **Solution**: Use `enable_nvtx=False` in production or reduce annotation granularity

#### Missing GPU Metrics
- **Problem**: No GPU utilization/memory data
- **Solution**: Add `--gpu-metrics-device=0` to nsys command

### ğŸ› ï¸ Advanced NVTX Configuration

#### Custom NVTX Annotations

```python
from src.encoding_101.models.nvtx_autoencoder import NVTXProfiler, NVTXColors

profiler = NVTXProfiler(enabled=True)

# Custom operation profiling
with profiler.annotate("Custom Operation", NVTXColors.METRICS):
    your_custom_function()

# Memory profiling
with profiler.profile_memory("Large Allocation"):
    large_tensor = torch.randn(10000, 10000).cuda()
```

#### Integration with Existing Models

```python
import nvtx
from contextlib import nullcontext

class YourModel(nn.Module):
    def __init__(self, enable_profiling=False):
        super().__init__()
        self.enable_profiling = enable_profiling
    
    def nvtx_annotate(self, name, color="white"):
        if self.enable_profiling:
            return nvtx.annotate(name, color=color)
        else:
            return nullcontext()
    
    def forward(self, x):
        with self.nvtx_annotate("Custom Forward", "yellow"):
            return self.layers(x)
```

### ğŸ§ª Advanced Profiling Commands

```bash
# Profile training for 30 seconds only
nsys profile --duration=30 --trace=nvtx,cuda python scripts/profile_training.py profile

# Profile with CPU context switching (advanced)
nsys profile --trace=nvtx,cuda,osrt --sample=cpu python scripts/profile_training.py profile

# Export specific metrics
nsys profile --trace=nvtx,cuda --output=training_profile python scripts/profile_training.py profile
```

---

## ğŸ“š Learning Resources

- **`learning/learn-nvtx-annotations.md`** - Comprehensive NVTX learning guide with exercises
- **`scripts/profile_training.py`** - Ready-to-use profiling scripts
- **[NVIDIA Nsight Systems](https://developer.nvidia.com/nsight-systems)** - Visual profiler for analyzing results
- **[PyTorch Profiler Guide](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)** - PyTorch profiling integration

## ğŸ¯ Key Features

### Model Architecture
- **Latent Space Encoding**: Configurable dimensionality (default: 128)
- **CIFAR-10 Optimization**: Optimized for 32x32x3 image reconstruction
- **PyTorch Lightning**: Modern training framework with automatic logging

### Evaluation Metrics
- **MAR@5**: Mean Average Recall at k=5 for embedding quality assessment
- **Reconstruction Loss**: MSE between input and reconstructed images
- **Visual Comparison**: Side-by-side original vs reconstructed image grids

---

**Need Help?** Check the comprehensive learning guide or run:
```bash
uv run python scripts/profile_training.py --help
```
