#!/bin/bash

# AI Learning - Docker Runtime (uv-powered)

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Enable Docker Bake for better build performance
export COMPOSE_BAKE=true

echo -e "${BLUE}üê≥ AI Learning - Docker Runtime (uv-powered)${NC}"
echo "============================================="

# Function to detect Linux distribution
detect_distro() {
    if [ -f /etc/os-release ]; then
        . /etc/os-release
        echo $ID
    elif [ -f /etc/redhat-release ]; then
        echo "rhel"
    elif [ -f /etc/debian_version ]; then
        echo "debian"
    else
        echo "unknown"
    fi
}

# Function to install Docker
install_docker() {
    echo -e "${YELLOW}üîß Installing Docker...${NC}"
    
    local distro=$(detect_distro)
    
    case $distro in
        "ubuntu"|"debian")
            # Update package index
            sudo apt-get update
            
            # Install required packages
            sudo apt-get install -y \
                ca-certificates \
                curl \
                gnupg \
                lsb-release
            
            # Add Docker's official GPG key
            sudo mkdir -p /etc/apt/keyrings
            curl -fsSL https://download.docker.com/linux/$distro/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
            
            # Set up the repository
            echo \
                "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/$distro \
                $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
            
            # Update package index again
            sudo apt-get update
            
            # Install Docker Engine
            sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
            
            # Add user to docker group
            sudo usermod -aG docker $USER
            
            echo -e "${GREEN}‚úÖ Docker installed successfully${NC}"
            echo -e "${YELLOW}‚ö†Ô∏è  Please log out and log back in for group changes to take effect${NC}"
            ;;
        "rhel"|"centos"|"fedora")
            # Install using yum/dnf
            if command -v dnf &> /dev/null; then
                PKG_MGR="dnf"
            else
                PKG_MGR="yum"
            fi
            
            sudo $PKG_MGR install -y yum-utils
            sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
            sudo $PKG_MGR install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
            
            # Start and enable Docker
            sudo systemctl start docker
            sudo systemctl enable docker
            
            # Add user to docker group
            sudo usermod -aG docker $USER
            
            echo -e "${GREEN}‚úÖ Docker installed successfully${NC}"
            ;;
        *)
            echo -e "${RED}‚ùå Unsupported distribution: $distro${NC}"
            echo "Please install Docker manually: https://docs.docker.com/engine/install/"
            exit 1
            ;;
    esac
}

# Function to install Docker Compose standalone
install_docker_compose() {
    echo -e "${YELLOW}üîß Installing Docker Compose...${NC}"
    
    # Get latest version
    local compose_version=$(curl -s https://api.github.com/repos/docker/compose/releases/latest | grep 'tag_name' | cut -d\" -f4)
    
    if [ -z "$compose_version" ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  Could not detect latest version, using v2.27.0${NC}"
        compose_version="v2.27.0"
    fi
    
    # Download and install
    sudo curl -L "https://github.com/docker/compose/releases/download/${compose_version}/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
    sudo chmod +x /usr/local/bin/docker-compose
    
    # Create symlink if needed
    if [ ! -f /usr/bin/docker-compose ]; then
        sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
    fi
    
    echo -e "${GREEN}‚úÖ Docker Compose ${compose_version} installed successfully${NC}"
}

# Function to install NVIDIA Docker
install_nvidia_docker() {
    echo -e "${YELLOW}üîß Installing NVIDIA Docker runtime...${NC}"
    
    local distro=$(detect_distro)
    
    case $distro in
        "ubuntu"|"debian")
            # Add NVIDIA package repositories
            distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
            
            # Handle GPG key - don't prompt if it exists
            if [ ! -f /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg ]; then
                curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
            else
                echo -e "${BLUE}‚ÑπÔ∏è  NVIDIA GPG key already exists, skipping...${NC}"
            fi
            
            # Handle repository list - don't duplicate if it exists
            if [ ! -f /etc/apt/sources.list.d/nvidia-container-toolkit.list ]; then
                curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
                    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
                    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list > /dev/null
            else
                echo -e "${BLUE}‚ÑπÔ∏è  NVIDIA repository already configured, skipping...${NC}"
            fi
            
            # Update package index
            sudo apt-get update
            
            # Install NVIDIA Docker
            sudo apt-get install -y nvidia-docker2
            
            # Restart Docker daemon to load new runtime
            echo -e "${BLUE}üîÑ Restarting Docker to load NVIDIA runtime...${NC}"
            sudo systemctl restart docker
            
            echo -e "${GREEN}‚úÖ NVIDIA Docker runtime installed successfully${NC}"
            ;;
        "rhel"|"centos"|"fedora")
            # Add NVIDIA package repositories
            distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
            
            # Handle repository file - don't duplicate if it exists
            if [ ! -f /etc/yum.repos.d/nvidia-container-toolkit.repo ]; then
                curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/nvidia-container-toolkit.repo | \
                    sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo > /dev/null
            else
                echo -e "${BLUE}‚ÑπÔ∏è  NVIDIA repository already configured, skipping...${NC}"
            fi
            
            # Install NVIDIA Docker
            if command -v dnf &> /dev/null; then
                sudo dnf install -y nvidia-docker2
            else
                sudo yum install -y nvidia-docker2
            fi
            
            # Restart Docker daemon to load new runtime
            echo -e "${BLUE}üîÑ Restarting Docker to load NVIDIA runtime...${NC}"
            sudo systemctl restart docker
            
            echo -e "${GREEN}‚úÖ NVIDIA Docker runtime installed successfully${NC}"
            ;;
        *)
            echo -e "${RED}‚ùå Unsupported distribution for NVIDIA Docker: $distro${NC}"
            echo "Please install NVIDIA Docker manually: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"
            exit 1
            ;;
    esac
}

# Function to ensure Docker is running
ensure_docker_running() {
    local command_name="${1:-}"
    
    # Check if Docker is running
    if ! docker info > /dev/null 2>&1; then
        echo -e "${RED}‚ùå Docker is not running. Please start Docker first.${NC}"
        echo "Try: sudo systemctl start docker"
        exit 1
    fi
    
    # Check NVIDIA runtime only for commands that need it (skip for cleanup)
    if [[ "$command_name" != "cleanup" ]]; then
        # Check if nvidia-docker is available
        if ! docker run --rm --gpus all nvidia/cuda:11.0-base-ubuntu20.04 nvidia-smi > /dev/null 2>&1; then
            echo -e "${YELLOW}‚ö†Ô∏è  NVIDIA Docker runtime not available.${NC}"
            echo -e "${BLUE}‚ÑπÔ∏è  GPU drivers will be provided by the NVIDIA PyTorch container.${NC}"
            
            # Check if nvidia-docker2 package is installed but not working
            nvidia_docker_installed=false
            if command -v apt-get &> /dev/null && dpkg -l | grep -q nvidia-docker2; then
                nvidia_docker_installed=true
                echo -e "${BLUE}‚ÑπÔ∏è  nvidia-docker2 package found${NC}"
            elif (command -v yum &> /dev/null || command -v dnf &> /dev/null) && rpm -qa | grep -q nvidia-docker2; then
                nvidia_docker_installed=true
                echo -e "${BLUE}‚ÑπÔ∏è  nvidia-docker2 package found${NC}"
            fi
            
            if [ "$nvidia_docker_installed" = true ]; then
                echo -e "${YELLOW}üîß NVIDIA Docker package installed but not working. This could be due to:${NC}"
                echo "  ‚Ä¢ Docker daemon needs to reload configuration"
                echo "  ‚Ä¢ Missing NVIDIA drivers on host"
                echo "  ‚Ä¢ Docker runtime configuration issues"
                echo ""
                echo -e "${BLUE}üí° You can try:${NC}"
                echo "  ‚Ä¢ sudo systemctl reload docker    # Reload config without restart"
                echo "  ‚Ä¢ sudo systemctl restart docker   # Full restart if reload doesn't work"
                echo "  ‚Ä¢ nvidia-smi                      # Check if NVIDIA drivers are working"
                echo ""
                echo -e "${YELLOW}‚ö†Ô∏è  Continuing without NVIDIA runtime - GPU will work via container drivers${NC}"
            else
                echo -e "${BLUE}üì¶ Installing NVIDIA Docker runtime...${NC}"
                install_nvidia_docker
                echo -e "${BLUE}üîÑ NVIDIA Docker runtime installed.${NC}"
                
                # Test again after installation
                if docker run --rm --gpus all nvidia/cuda:11.0-base-ubuntu20.04 nvidia-smi > /dev/null 2>&1; then
                    echo -e "${GREEN}‚úÖ NVIDIA Docker runtime is now working${NC}"
                else
                    echo -e "${YELLOW}‚ö†Ô∏è  NVIDIA Docker runtime still not working after installation${NC}"
                    echo -e "${BLUE}‚ÑπÔ∏è  This is often due to missing NVIDIA drivers on the host${NC}"
                    echo -e "${BLUE}‚ÑπÔ∏è  GPU functionality will be provided by the container's NVIDIA PyTorch base image${NC}"
                fi
            fi
        else
            echo -e "${GREEN}‚úÖ NVIDIA Docker runtime already working${NC}"
        fi
        
        echo -e "${GREEN}‚úÖ Docker and NVIDIA runtime are available${NC}"
    else
        echo -e "${GREEN}‚úÖ Docker is running and ready for cleanup${NC}"
    fi
}

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo -e "${YELLOW}‚ö†Ô∏è  Docker not found. Installing Docker...${NC}"
    install_docker
    echo -e "${BLUE}üîÑ Please run this script again after logging out and back in.${NC}"
    exit 0
fi

# Check if Docker Compose is available
if ! docker compose version &> /dev/null; then
    echo -e "${YELLOW}‚ö†Ô∏è  Docker Compose not found. Installing Docker Compose...${NC}"
    install_docker_compose
    
    # Verify installation worked
    if ! docker compose version &> /dev/null; then
        echo -e "${RED}‚ùå Docker Compose installation failed. Please install manually.${NC}"
        echo "Visit: https://docs.docker.com/compose/install/"
        exit 1
    fi
    
    echo -e "${GREEN}‚úÖ Docker Compose verified working${NC}"
fi

# Docker and NVIDIA runtime checks are now handled per-command in ensure_docker_running()

# Function to build Docker image when needed
build_image_if_needed() {
    echo -e "${YELLOW}üî® Building Docker image with uv...${NC}"
    docker compose build ai-learning
}

# Function to run training
run_training() {
    local model_type=${1:-"vanilla"}
    local epochs=${2:-10}
    local batch_size=${3:-64}
    local job_id=${4:-""}
    local num_workers=${5:-""}
    
    build_image_if_needed
    
    echo -e "${BLUE}üöÄ Starting training with:${NC}"
    echo "  Model: $model_type"
    echo "  Epochs: $epochs"
    echo "  Batch size: $batch_size"
    
    if [ "$model_type" == "nvtx" ]; then
        # Set output filename
        local output_name="training_profile_${epochs}ep"
        if [ -n "$job_id" ]; then
            output_name="${job_id}_${epochs}ep"
        fi
        
        # Set default num_workers for profiling mode
        local workers=${num_workers:-"2"}  # Default to 2 workers for better performance
        
        echo -e "${YELLOW}üîç NVTX profiling enabled with nsys capture${NC}"
        echo -e "${BLUE}üìÅ Profiler output will be saved to: ./profiling_output/${output_name}.nsys-rep${NC}"
        echo -e "${BLUE}üîß Using $workers DataLoader workers${NC}"
        echo -e "${BLUE}üìä GPU metrics: Graphics, DRAM, NVLink, PCIe, SM, Tensor Core${NC}"
        docker compose run --rm profiling \
            nsys profile --trace=nvtx,cuda,osrt,cublas,cudnn \
            --backtrace=dwarf \
            --sample=cpu \
            --cpuctxsw=process-tree \
            --force-overwrite=true \
            --cuda-memory-usage=true \
            --gpu-metrics-device=all \
            --gpu-metrics-frequency=10000 \
            --gpu-metrics-set=gr,dram,nvl,pcie,sm,tensor \
            --wait=all \
            --delay=2 \
            --duration=300 \
            --output=/app/profiling_output/${output_name} \
            uv run scripts/profile_training.py profile \
            --max-epochs $epochs \
            --batch-size $batch_size \
            --num-workers $workers \
            --enable-nvtx
    else
        echo -e "${GREEN}üéØ Standard training${NC}"
        docker compose run --rm ai-learning \
            uv run python -m src.encoding_101.01_vanilla_autoencoder train-ae \
            --max-epochs $epochs \
            --batch-size $batch_size
    fi
}

# Function to run NVTX profiling
run_profiling() {
    local job_id=${1:-""}
    local num_workers=${2:-"2"}  # Default to 2 workers
    local output_name="training_profile"
    if [ -n "$job_id" ]; then
        output_name="${job_id}_3ep"
    fi
    
    build_image_if_needed
    
    echo -e "${YELLOW}üîç Running NVTX profiling session...${NC}"
    echo -e "${BLUE}üìÅ Profiler output will be saved to: ./profiling_output/${output_name}.nsys-rep${NC}"
    echo -e "${BLUE}üîß Using $num_workers DataLoader workers${NC}"
    echo -e "${BLUE}üìä GPU metrics: Graphics, DRAM, NVLink, PCIe, SM, Tensor Core${NC}"
    docker compose run --rm profiling \
        nsys profile --trace=nvtx,cuda,osrt,cublas,cudnn \
        --backtrace=dwarf \
        --sample=cpu \
        --cpuctxsw=process-tree \
        --force-overwrite=true \
        --cuda-memory-usage=true \
        --gpu-metrics-device=all \
        --gpu-metrics-frequency=10000 \
        --gpu-metrics-set=gr,dram,nvl,pcie,sm,tensor \
        --wait=all \
        --delay=2 \
        --duration=300 \
        --output=/app/profiling_output/${output_name} \
        uv run scripts/profile_training.py profile --max-epochs 3 --num-workers $num_workers
    
    echo -e "${GREEN}‚úÖ Profiling complete! Check ./profiling_output/ for results${NC}"
}

# Function to run simplified NVTX profiling (avoids MMAP issues)
run_simple_profiling() {
    local job_id=${1:-""}
    local output_name="simple_profile"
    if [ -n "$job_id" ]; then
        output_name="${job_id}_simple"
    fi
    
    build_image_if_needed
    
    echo -e "${YELLOW}üîç Running simplified NVTX profiling session...${NC}"
    echo -e "${BLUE}üìÅ Profiler output will be saved to: ./profiling_output/${output_name}.nsys-rep${NC}"
    echo -e "${BLUE}üìä GPU metrics: Graphics, DRAM, SM utilization${NC}"
    docker compose run --rm profiling \
        nsys profile --trace=nvtx,cuda \
        --force-overwrite=true \
        --cuda-memory-usage=true \
        --gpu-metrics-device=all \
        --gpu-metrics-frequency=20000 \
        --gpu-metrics-set=gr,dram,sm \
        --process-scope=system-wide \
        --output=/app/profiling_output/${output_name} \
        uv run scripts/profile_training.py profile --max-epochs 2
    
    echo -e "${GREEN}‚úÖ Simplified profiling complete! Check ./profiling_output/ for results${NC}"
}

# Function to run GPU-focused NVTX profiling (maximum GPU insights)
run_gpu_profiling() {
    local job_id=${1:-""}
    local output_name="gpu_profile"
    if [ -n "$job_id" ]; then
        output_name="${job_id}_gpu"
    fi
    
    build_image_if_needed
    
    echo -e "${YELLOW}üîç Running GPU-focused NVTX profiling session...${NC}"
    echo -e "${BLUE}üìÅ Profiler output will be saved to: ./profiling_output/${output_name}.nsys-rep${NC}"
    echo -e "${BLUE}üöÄ Maximum GPU metrics collection enabled${NC}"
    echo -e "${BLUE}üìä GPU metrics: All available (GR, DRAM, NVL, PCIe, SM, Tensor, Power, Clocks)${NC}"
    docker compose run --rm profiling \
        nsys profile --trace=nvtx,cuda,osrt,cublas,cudnn,opengl \
        --force-overwrite=true \
        --cuda-memory-usage=true \
        --gpu-metrics-device=all \
        --gpu-metrics-frequency=5000 \
        --gpu-metrics-set=all \
        --wait=all \
        --delay=3 \
        --duration=180 \
        --output=/app/profiling_output/${output_name} \
        uv run scripts/profile_training.py profile --max-epochs 2 --num-workers 2 --batch-size 128
    
    echo -e "${GREEN}‚úÖ GPU profiling complete! Check ./profiling_output/ for comprehensive GPU metrics${NC}"
}

# Function to start TensorBoard
start_tensorboard() {
    build_image_if_needed
    
    echo -e "${BLUE}üìä Starting TensorBoard...${NC}"
    docker compose up -d tensorboard
    echo -e "${GREEN}‚úÖ TensorBoard running at http://localhost:6007${NC}"
}

# Function to run interactive shell
run_shell() {
    build_image_if_needed
    
    echo -e "${BLUE}üêö Starting interactive shell...${NC}"
    docker compose run --rm ai-learning bash
}

# Function to run uv commands
run_uv() {
    build_image_if_needed
    
    echo -e "${BLUE}üîß Running uv command: $*${NC}"
    docker compose run --rm ai-learning uv "$@"
}

# Function to sync dependencies
sync_deps() {
    build_image_if_needed
    
    echo -e "${YELLOW}üì¶ Syncing dependencies with uv...${NC}"
    docker compose run --rm ai-learning uv sync --locked
    echo -e "${GREEN}‚úÖ Dependencies synced${NC}"
}

# Function to launch Nsight Systems UI
run_nsys_ui() {
    local profile_file="$1"
    
    echo -e "${BLUE}üìä Nsight Systems UI Launcher (Containerized)${NC}"
    echo "=============================================="
    
    # Check if X11 forwarding is possible
    if [ -z "$DISPLAY" ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  No DISPLAY environment variable set${NC}"
        echo "For GUI applications, you need X11 forwarding:"
        echo ""
        echo -e "${BLUE}Local desktop:${NC}"
        echo "  export DISPLAY=:0"
        echo ""
        echo -e "${BLUE}Remote SSH connection:${NC}"
        echo "  ssh -X username@hostname"
        echo "  # or"
        echo "  ssh -Y username@hostname"
        echo ""
        echo -e "${BLUE}For headless servers (using X11 over network):${NC}"
        echo "  # Install X11 forwarding on client"
        echo "  # Then connect with: ssh -X username@hostname"
        echo ""
        echo -e "${YELLOW}üí° You can still run this command - it will show the error but might work in some environments${NC}"
        echo ""
    fi
    
    # Check if profiling_output directory exists
    if [ ! -d "./profiling_output" ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  No profiling_output directory found${NC}"
        echo "Run some profiling first:"
        echo "  bin/run train-nvtx 5"
        echo "  bin/run profile"
        return 1
    fi
    
    # List available profile files (both .qdrep and .nsys-rep)
    local profile_files=(./profiling_output/*.qdrep ./profiling_output/*.nsys-rep)
    
    # Filter out non-existent files (bash expands to literal *.extension if no files match)
    local existing_files=()
    for file in "${profile_files[@]}"; do
        if [ -f "$file" ]; then
            existing_files+=("$file")
        fi
    done
    
    # Check if any profile files exist
    if [ ${#existing_files[@]} -eq 0 ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  No .qdrep or .nsys-rep files found in profiling_output/${NC}"
        echo "Run some profiling first:"
        echo "  bin/run train-nvtx 5"
        echo "  bin/run profile"
        echo ""
        echo -e "${BLUE}Available files in profiling_output/:${NC}"
        ls -la ./profiling_output/ 2>/dev/null || echo "  (directory empty)"
        return 1
    fi
    
    # Use existing files array
    profile_files=("${existing_files[@]}")
    
    # If no specific file provided, show options
    if [ -z "$profile_file" ]; then
        echo -e "${GREEN}üìÅ Available profile files:${NC}"
        echo ""
        local i=1
        for file in "${profile_files[@]}"; do
            local basename_file=$(basename "$file")
            local size=$(du -h "$file" 2>/dev/null | cut -f1)
            local date=$(stat -c %y "$file" 2>/dev/null | cut -d' ' -f1,2 | cut -d'.' -f1)
            echo "  $i) $basename_file ($size, $date)"
            ((i++))
        done
        echo ""
        echo -e "${BLUE}Usage:${NC}"
        echo "  bin/run nsys-ui                          # Show this list"
        echo "  bin/run nsys-ui <filename>               # Open specific file"
        echo "  bin/run nsys-ui 1                       # Open file by number"
        echo "  bin/run nsys-ui latest                   # Open most recent file"
        echo ""
        return 0
    fi
    
    # Handle different input types to determine target file
    local target_file=""
    local container_path=""
    
    if [ "$profile_file" = "latest" ]; then
        # Find the most recent file (both .qdrep and .nsys-rep)
        target_file=$(ls -t ./profiling_output/*.qdrep ./profiling_output/*.nsys-rep 2>/dev/null | head -n1)
        if [ -f "$target_file" ]; then
            container_path="/app/profiling_output/$(basename "$target_file")"
            echo -e "${BLUE}üîç Opening most recent profile: $(basename "$target_file")${NC}"
        else
            echo -e "${RED}‚ùå No profile files found${NC}"
            return 1
        fi
    elif [[ "$profile_file" =~ ^[0-9]+$ ]]; then
        # Handle numeric selection
        local file_index=$((profile_file - 1))
        if [ $file_index -ge 0 ] && [ $file_index -lt ${#profile_files[@]} ]; then
            target_file="${profile_files[$file_index]}"
            container_path="/app/profiling_output/$(basename "$target_file")"
            echo -e "${BLUE}üîç Opening profile #$profile_file: $(basename "$target_file")${NC}"
        else
            echo -e "${RED}‚ùå Invalid file number: $profile_file${NC}"
            echo "Available files: 1-${#profile_files[@]}"
            return 1
        fi
    else
        # Handle filename (support both .qdrep and .nsys-rep extensions)
        local found_file=""
        
        # Try exact filename first (handles full paths like profiling_output/file.nsys-rep)
        if [ -f "./$profile_file" ]; then
            found_file="./$profile_file"
        # Try in profiling_output directory
        elif [ -f "./profiling_output/$profile_file" ]; then
            found_file="./profiling_output/$profile_file"
        # Try with .qdrep extension
        elif [ -f "./profiling_output/${profile_file%.qdrep}.qdrep" ]; then
            found_file="./profiling_output/${profile_file%.qdrep}.qdrep"
        # Try with .nsys-rep extension  
        elif [ -f "./profiling_output/${profile_file%.nsys-rep}.nsys-rep" ]; then
            found_file="./profiling_output/${profile_file%.nsys-rep}.nsys-rep"
        # Try without any extension, adding both in profiling_output
        elif [ -f "./profiling_output/${profile_file}.qdrep" ]; then
            found_file="./profiling_output/${profile_file}.qdrep"
        elif [ -f "./profiling_output/${profile_file}.nsys-rep" ]; then
            found_file="./profiling_output/${profile_file}.nsys-rep"
        # Try removing profiling_output/ prefix if user included it
        elif [[ "$profile_file" == profiling_output/* ]]; then
            local basename_only="${profile_file#profiling_output/}"
            if [ -f "./profiling_output/$basename_only" ]; then
                found_file="./profiling_output/$basename_only"
            fi
        fi
        
        if [ -n "$found_file" ]; then
            target_file="$found_file"
            container_path="/app/profiling_output/$(basename "$target_file")"
            echo -e "${BLUE}üîç Opening profile: $(basename "$target_file")${NC}"
        else
            echo -e "${RED}‚ùå File not found: $profile_file${NC}"
            echo "Run 'bin/run nsys-ui' to see available files"
            echo ""
            echo -e "${BLUE}Available files in profiling_output/:${NC}"
            ls -la ./profiling_output/ 2>/dev/null || echo "  (directory empty)"
            return 1
        fi
    fi
    
    # Launch nsys-ui in container with GUI forwarding
    echo -e "${GREEN}üöÄ Launching Nsight Systems UI in container...${NC}"
    echo "Host file: $target_file"
    echo "Container path: $container_path"
    echo ""
    
    # Build image only when we actually need to run the container
    build_image_if_needed
    
    # Check if we're on a system that might need xhost permissions
    if command -v xhost &> /dev/null && [ -n "$DISPLAY" ]; then
        echo -e "${BLUE}üîß Setting up X11 permissions...${NC}"
        xhost +local:docker >/dev/null 2>&1 || true
    fi
    
    echo -e "${BLUE}üí° Note: nsys-ui will run inside the container${NC}"
    echo -e "${BLUE}üí° Make sure X11 forwarding is working if using SSH${NC}"
    echo ""
    
    # Run nsys-ui in the profiling container with GUI support
    echo -e "${GREEN}üöÄ Launching Nsight Systems UI in container...${NC}"
    echo "Host file: $target_file"
    echo "Container path: $container_path"
    echo ""
    
    # Build image only when we actually need to run the container
    build_image_if_needed
    
    # Check if we're on a system that might need xhost permissions
    if command -v xhost &> /dev/null && [ -n "$DISPLAY" ]; then
        echo -e "${BLUE}üîß Setting up X11 permissions...${NC}"
        xhost +local:docker >/dev/null 2>&1 || true
    fi
    
    echo -e "${BLUE}üí° Note: nsys-ui will run inside the container${NC}"
    echo -e "${BLUE}üí° Make sure X11 forwarding is working if using SSH${NC}"
    echo ""
    
    # Run nsys-ui in the profiling container with GUI support
    docker compose run --rm \
        -e DISPLAY="$DISPLAY" \
        -v /tmp/.X11-unix:/tmp/.X11-unix:rw \
        profiling \
        nsys-ui "$container_path"
    
    echo -e "${GREEN}‚úÖ Nsight Systems UI session ended${NC}"
}

# Function to clean up Docker resources
docker_cleanup() {
    echo -e "${BLUE}üßπ Docker Cleanup${NC}"
    echo "=================="
    
    # Show current disk usage
    echo -e "${YELLOW}üìä Current Docker disk usage:${NC}"
    docker system df
    echo ""
    
    # Count dangling images
    local dangling_count=$(docker images --filter "dangling=true" -q | wc -l)
    echo -e "${BLUE}üîç Found $dangling_count dangling images (with <none> tag)${NC}"
    
    if [ "$dangling_count" -gt 0 ]; then
        echo -e "${YELLOW}üóëÔ∏è  Removing dangling images...${NC}"
        docker image prune -f
        echo -e "${GREEN}‚úÖ Removed dangling images${NC}"
    else
        echo -e "${GREEN}‚úÖ No dangling images found${NC}"
    fi
    
    echo ""
    
    # Clean up unused containers
    echo -e "${YELLOW}üóëÔ∏è  Removing stopped containers...${NC}"
    docker container prune -f
    
    # Clean up unused networks
    echo -e "${YELLOW}üóëÔ∏è  Removing unused networks...${NC}"
    docker network prune -f
    
    # Clean up unused volumes (be careful with this)
    local volume_count=$(docker volume ls -qf dangling=true | wc -l)
    if [ "$volume_count" -gt 0 ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  Found $volume_count unused volumes${NC}"
        echo -e "${BLUE}üí° To clean volumes: docker volume prune -f${NC}"
        echo -e "${BLUE}üí° (Not auto-cleaned to preserve data)${NC}"
    else
        echo -e "${GREEN}‚úÖ No unused volumes found${NC}"
    fi
    
    echo ""
    echo -e "${YELLOW}üìä Disk usage after cleanup:${NC}"
    docker system df
    
    echo ""
    echo -e "${GREEN}‚úÖ Docker cleanup complete!${NC}"
    echo -e "${BLUE}üí° For aggressive cleanup: docker system prune -a${NC}"
}

# Parse command line arguments
case "${1:-help}" in
    "train")
        ensure_docker_running "train"
        run_training "${2:-vanilla}" "${3:-10}" "${4:-64}"
        ;;
    "train-nvtx")
        ensure_docker_running "train-nvtx"
        run_training "nvtx" "${2:-5}" "${3:-64}" "${4:-}" "${5:-}"
        ;;
    "profile")
        ensure_docker_running "profile"
        run_profiling "${2:-}" "${3:-}"
        ;;
    "profile-simple")
        ensure_docker_running "profile-simple"
        run_simple_profiling "${2:-}"
        ;;
    "profile-fast")
        ensure_docker_running "profile-fast"
        run_profiling "${2:-fast}" "4"  # Use 4 workers for maximum performance
        ;;
    "profile-gpu")
        ensure_docker_running "profile-gpu"
        run_gpu_profiling "${2:-}"
        ;;
    "test-dataloader")
        ensure_docker_running "test-dataloader"
        build_image_if_needed
        echo -e "${YELLOW}üß™ Testing DataLoader for segmentation faults...${NC}"
        docker compose run --rm profiling uv run scripts/validate_dataloader.py "${2:-256}" "${3:-0}"
        ;;
    "tensorboard")
        ensure_docker_running "tensorboard"
        start_tensorboard
        ;;
    "shell")
        ensure_docker_running "shell"
        run_shell
        ;;
    "sync")
        ensure_docker_running "sync"
        sync_deps
        ;;
    "uv")
        ensure_docker_running "uv"
        shift
        run_uv "$@"
        ;;
    "nsys-ui")
        ensure_docker_running "nsys-ui"
        shift
        run_nsys_ui "$@"
        ;;
    "cleanup")
        ensure_docker_running "cleanup"
        docker_cleanup
        ;;
    "help"|*)
        echo -e "${BLUE}Usage: $0 [COMMAND] [OPTIONS]${NC}"
        echo ""
        echo "Commands:"
        echo "  train [epochs] [batch_size]     - Train vanilla autoencoder (default: 10 epochs, 64 batch)"
        echo "  train-nvtx [epochs] [batch_size] [job_id] [num_workers] - Train with NVTX profiling + nsys capture (default: 5 epochs, 64 batch, 2 workers)"
        echo "  profile [job_id] [num_workers]  - Run full NVTX profiling session (3 epochs, default: 2 workers)"
        echo "  profile-simple [job_id]         - Run simplified NVTX profiling (avoids MMAP issues)"
        echo "  profile-fast [job_id]           - Run fast NVTX profiling (4 workers, may have segfaults)"
        echo "  profile-gpu [job_id]            - Run GPU-focused profiling (comprehensive GPU metrics)"
        echo "  test-dataloader [batch_size] [num_workers] - Test DataLoader for segmentation faults (default: 256 batch, 0 workers)"
        echo "  tensorboard                     - Start TensorBoard service"
        echo "  shell                          - Start interactive bash shell"
        echo "  sync                           - Sync dependencies with uv"
        echo "  uv [command]                   - Run any uv command"
        echo "  nsys-ui [filename]              - Launch Nsight Systems UI"
        echo "  cleanup                        - Clean up Docker resources"
        echo "  help                           - Show this help message"
        echo ""
        echo "Examples:"
        echo "  $0 train 20 128                - Train for 20 epochs with batch size 128"
        echo "  $0 train-nvtx 5 64             - Train with NVTX for 5 epochs"
        echo "  $0 train-nvtx 5 64 my_experiment - Train with NVTX and custom job ID"
        echo "  $0 train-nvtx 5 256 gpu_test 4 - Train with 4 workers for faster data loading"
        echo "  $0 profile                     - Run profiling session (2 workers default)"
        echo "  $0 profile my_job              - Run profiling with custom job ID"
        echo "  $0 profile my_job 4            - Run profiling with 4 workers"
        echo "  $0 profile-simple              - Run simplified profiling (avoids MMAP errors)"
        echo "  $0 profile-fast                - Run fast profiling (4 workers, riskier but faster)"
        echo "  $0 profile-gpu gpu_analysis     - Run comprehensive GPU metrics profiling"
        echo "  $0 test-dataloader             - Test DataLoader stability before profiling"
        echo "  $0 sync                        - Sync project dependencies"
        echo "  $0 uv add torch                - Add PyTorch dependency"
        echo "  $0 shell                       - Interactive development"
        echo "  $0 nsys-ui                     - List available profiling files"
        echo "  $0 nsys-ui latest              - Open most recent profile"
        echo "  $0 nsys-ui training_profile_5ep - Open specific profile file"
        echo "  $0 cleanup                     - Remove dangling Docker images"
        echo ""
        echo "Installation:"
        echo "  This script will automatically install Docker, Docker Compose, and NVIDIA Docker runtime"
        echo "  if they are not already installed on your system."
        ;;
esac
